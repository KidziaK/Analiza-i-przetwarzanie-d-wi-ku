sigma <- 1
CovMatrix <- diag(p)
for (i in 1:p) {
m <- matrix(0, p, p)
m <- m[abs(row(m) - col(m)) == i] <- (0.5)^i
CovMatrix <- CovMatrix + m
}
CovMatrix
p <- 4
n <- 1000
sigma <- 1
CovMatrix <- diag(p)
for (i in 2:p) {
m <- matrix(0, p, p)
m <- m[abs(row(m) - col(m)) == i] <- (0.5)^i
CovMatrix <- CovMatrix + m
}
CovMatrix
CovMatrix <- diag(p)
CovMatrix
m <- matrix(0, p, p)
m <- m[abs(row(m) - col(m)) == i] <- (0.5)
m
m <- matrix(0, p, p)
m <- m[abs(row(m) - col(m)) == 1] <- (0.5)
m
m <- matrix(0, p, p)
m
row(m)
m <- matrix(0, p, p)
m[abs(row(m) - col(m)) == 1] <- (0.5)
m
p <- 4
n <- 1000
sigma <- 1
CovMatrix <- diag(p)
for (i in 2:p) {
m <- matrix(0, p, p)
m[abs(row(m) - col(m)) == i] <- (0.5)^i
CovMatrix <- CovMatrix + m
}
CovMatrix
p <- 4
n <- 1000
sigma <- 1
CovMatrix <- diag(p)
for (i in 1:p) {
m <- matrix(0, p, p)
m[abs(row(m) - col(m)) == i] <- (0.5)^i
CovMatrix <- CovMatrix + m
}
CovMatrix
# Załaduj Dane
df <- read.table("seeds_dataset.txt",sep = " ",h=TRUE)
df
View(df)
df <- read.table("seeds_dataset.txt",sep = " ",h=TRUE)
# a)
glm(Class~area,data = df, family = "binomial")
m1 <- glm(Class~area,data = df, family = "binomial")
predict(m1,type = 'Class')
# a)
m1 <- glm(Class~area,data = df, family = "binomial")
predict(m1,type = 'response')
exp(m1$coefficients[names(m1$coefficients)=='area'])
m1$beta
m1$Beta
coef(m1)
b0 = coef(m1)[1]
b1 = coef(m1)[2]
b0
b1
x <- (ln(7/3) - b0)/b1
x <- (log(7/3) - b0)/b1
x
log(2)
# c)
m2 <- glm(Class~., data = df, family = "binomial")
m2_BIC <- stepAIC(m2, direction = "backward", k = log(n)) #BIC
m2_BIC
summary(m2_BIC)
X1 <- model.matrix(m2)
X2 <- model.matrix(m2_BIC)
n <- nrow(data)
p1 <- ncol(X1)
p2 <- ncol(X2)
SSE1 <- sum(m2$residuals^2)
SSE2 <- sum(m2_BIC$residuals^2)
Fstat <- (SSE1 - SSE2)/(p2 - p1) / (SSE2/(n - p2))
1-pf(Fstat,p2 - p1,n-p2)
anova(m2, m1, test="F")
sum_m2_BIC <-s ummary(m2_BIC)
1 - pchisq(sum_m2_BIC$null.deviance-sum_m2_BIC$deviance,sum_m2_BIC$df.null-sum_m2_BIC$df.residual)
sum_m2_BIC <- summary(m2_BIC)
1 - pchisq(sum_m2_BIC$null.deviance-sum_m2_BIC$deviance,sum_m2_BIC$df.null-sum_m2_BIC$df.residual)
T <- sum_m2_BIC$null.deviance - sum_m2_BIC$deviance
T
sum_m2_BIC$df.null - sum_m2_BIC$df.residual
K_alpha <- qchisq(0.95, sum_m2_BIC$df.null - sum_m2_BIC$df.residual)
K_alpha
df <- read.table("seeds_dataset.txt",sep = " ", header = TRUE)
# Oświadczam, że niniejsza praca stanowiąca podstawę do uznania osiągnięcia efektów uczenia
# się z przedmiotu Metody Statystyki Obliczeniowej została wykonana przeze mnie samodzielnie.
# Mikołaj Kida 276944
# Kolokwium 2
library(MASS)
library(glmnet)
library(dplyr)
#______________________________________________________________________________
# Zadanie 1)
# a)
p <- 200
n <- 1000
sigma <- 1
CovMatrix <- diag(p)
for (i in 1:p) {
m <- matrix(0, p, p)
m[abs(row(m) - col(m)) == i] <- (0.5)^i
CovMatrix <- CovMatrix + m
}
# Wygeneruj próbkę
x <- mvrnorm(n, mu = seq(0.01,5,0.025), Sigma = CovMatrix)
eps <- rnorm(n, 0, sigma)
beta <- c(rep(1, 10), rep(0, 190))
y <- x %*% beta + eps
# Utwórz ramkę danych
dane <- data.frame(y, x)
# Podziel dane na podzbiory
rows <- sample(nrow(dane),n/2)
treningowy <- dane[rows,]
walidacyjny <- dane[-rows,]
# c)
# Cross Validacja
cv_model <- cv.glmnet(x = data.matrix(treningowy[,-1]), y = treningowy[,1], alpha = 0.5)
# Dopasowany model
model <- glmnet(x = data.matrix(treningowy[,-1]), y = treningowy[,1], alpha = 0.5, lambda = cv_model$lambda.min)
cv_model <- cv.glmnet(x = data.matrix(walidacyjny[,-1]), y = walidacyjny[,1], alpha = 0.5)
cv_walidacyjny <- cv.glmnet(x = data.matrix(walidacyjny[,-1]), y = walidacyjny[,1], alpha = 0.5)
# Oświadczam, że niniejsza praca stanowiąca podstawę do uznania osiągnięcia efektów uczenia
# się z przedmiotu Metody Statystyki Obliczeniowej została wykonana przeze mnie samodzielnie.
# Mikołaj Kida 276944
# Kolokwium 2
library(MASS)
library(glmnet)
library(dplyr)
#______________________________________________________________________________
# Zadanie 1)
# a)
p <- 200
n <- 1000
sigma <- 1
CovMatrix <- diag(p)
for (i in 1:p) {
m <- matrix(0, p, p)
m[abs(row(m) - col(m)) == i] <- (0.5)^i
CovMatrix <- CovMatrix + m
}
# Wygeneruj próbkę
x <- mvrnorm(n, mu = seq(0.01,5,0.025), Sigma = CovMatrix)
eps <- rnorm(n, 0, sigma)
beta <- c(rep(1, 10), rep(0, 190))
y <- x %*% beta + eps
# Utwórz ramkę danych
dane <- data.frame(y, x)
# Podziel dane na podzbiory
rows <- sample(nrow(dane),n/2)
treningowy <- dane[rows,]
walidacyjny <- dane[-rows,]
# c)
# Cross Validacja
cv_treningowy <- cv.glmnet(x = data.matrix(treningowy[,-1]), y = treningowy[,1], alpha = 0.5)
# Dopasowany model
model <- glmnet(x = data.matrix(treningowy[,-1]), y = treningowy[,1], alpha = 0.5, lambda = cv_treningowy$lambda.min)
# d)
# Cross Validacja
cv_walidacyjny <- cv.glmnet(x = data.matrix(walidacyjny[,-1]), y = walidacyjny[,1], alpha = 0.5)
# Optymalne lambda
cv_walidacyjny$lambda.min
plot(cv_walidacyjny)
# Oświadczam, że niniejsza praca stanowiąca podstawę do uznania osiągnięcia efektów uczenia
# się z przedmiotu Metody Statystyki Obliczeniowej została wykonana przeze mnie samodzielnie.
# Mikołaj Kida 276944
# Kolokwium 2
library(MASS)
library(glmnet)
library(dplyr)
#______________________________________________________________________________
# Zadanie 1)
# a)
p <- 200
n <- 1000
sigma <- 1
CovMatrix <- diag(p)
for (i in 1:p) {
m <- matrix(0, p, p)
m[abs(row(m) - col(m)) == i] <- (0.5)^i
CovMatrix <- CovMatrix + m
}
# Wygeneruj próbkę
x <- mvrnorm(n, mu = seq(0.01,5,0.025), Sigma = CovMatrix)
eps <- rnorm(n, 0, sigma)
beta <- c(rep(1, 10), rep(0, 190))
y <- x %*% beta + eps
# Utwórz ramkę danych
dane <- data.frame(y, x)
# Podziel dane na podzbiory
rows <- sample(nrow(dane),n/2)
treningowy <- dane[rows,]
walidacyjny <- dane[-rows,]
# c)
# Cross Validacja
cv_treningowy <- cv.glmnet(x = data.matrix(treningowy[,-1]), y = treningowy[,1], alpha = 0.5)
# Dopasowany model
model <- glmnet(x = data.matrix(treningowy[,-1]), y = treningowy[,1], alpha = 0.5, lambda = cv_treningowy$lambda.min)
# d)
# Cross Validacja
cv_walidacyjny <- cv.glmnet(x = data.matrix(walidacyjny[,-1]), y = walidacyjny[,1], alpha = 0.5)
# Optymalne lambda
cv_walidacyjny$lambda.min
plot(cv_walidacyjny)
# e)
istotne <- sum(which(model$beta != 0) <= 10)
nieistotne <- sum(which(model$beta != 0) > 10)
istotne
niesistotne
nieistotne
# Procent zmiennych nieistotnych wybranych do modelu
nieistotne/190
# Procent zmienncyh istotnych wybranych do modelu
istotne/10
install.packages("quantmod")
dane <- read.table("DOWJ.DAT")
dane <- read.table("DOWJ.DAT")
install.packages("quantmod")dane
dane
# a)
dane_ts <- ts(data=dane)
# a)
dane_ts <- ts(data=dane, start="28-08-1972", end="18-12-1972")
dane_ts
dane
# a)
dane_ts <- ts(data=dane, start=ymd("1972-08-28"), end=ymd("1972-12-18"))
library(lubridate)
# a)
dane_ts <- ts(data=dane, start=ymd("1972-08-28"), end=ymd("1972-12-18"))
dane_ts
# b)
plot(dane_ts)
# a)
dane_ts <- ts(data = dane, start = decimal_date(ymd("1972-08-28")), end = decimal_date(ymd("1972-12-18")))
dane_ts <- ts(data = dane, start = decimal_date(ymd("1972-08-28")), end = decimal_date(ymd("1972-12-18")))
# b)
plot(dane_ts)
# a)
dane_ts <- ts(data = dane, start = ymd("1972-08-28"), end = ymd("1972-12-18"))
# b)
plot(dane_ts)
# a)
dane_ts <- ts(data = dane, start = ymd("1972-08-28"), frequency = 365)
# b)
plot(dane_ts)
# a)
dane_ts <- ts(data = dane, start = ymd("1972-08-28"), end = ymd("1972-12-18"))
# b)
plot(dane_ts)
dane
# a)
dane_ts <- ts(data = dane, start = decimal_date(ymd("1972-08-28")), frequency = 365)
# b)
plot(dane_ts)
# c)
acf(dane_ts)
# c)
acf(dane_ts)
# d)
diff(dane_ts)
# d)
dane_sz <- diff(dane_ts)
# e)
plot(dane_sz)
Box.test(dane_sz, lag = 10, type = "Ljung")
# f)
acf(dane_sz)
pacf(dane_sz)
# f)
acf(dane_sz)
pacf(dane_sz)
dane_sz[-nrow(dane_sz)]
sz_2 <- c(NA, dane_sz[-nrow(dane_sz)])
AR <- lm(dane_sz ~ sz_2)
AR$coefficients
sc_AR <- AR$coefficients[1] + AR$coefficients * sz_2
sc_AR <- AR$coefficients[1] + AR$coefficients[2] * sz_2
plot(sc_AR)
sc_AR <- ts(AR$coefficients[1] + AR$coefficients[2] * sz_2)
plot(sc_AR)
acf(sc_AR)
sc_AR
plot(AR$residuals)
acf(AR)
sz_2 <- c(NA, dane_sz[-nrow(dane_sz)])
AR <- lm(dane_sz ~ sz_2)
acf(AR$residuals)
MA <- arima(dane_sz, c(1,0,0))
acf(MA$residuals)
acf(AR$residuals)
MA <- arima(dane_sz, c(0,0,2))
acf(MA$residuals)
Box.test(MA, lag = 10, type = "Ljung")
Box.test(MA$residuals, lag = 10, type = "Ljung")
Box.test(AR$residuals, lag = 10, type = "Ljung")
library(shiny); source('C:/Users/KidziaK/Desktop/Analiza dźwięku/app.R')
getwd()
source('Analiza dźwięku/app.R')
source('AIPSD/app.R')
dane <- read.csv("follic_short.csv")
setwd("~/")
dane <- read.csv("follic_short.csv")
dane <- read.csv("follic_short_cr.csv")
dane
install.packages(c("KMsurv", "survMisc"))
library(shiny); source('Analiza-i-przetwarzanie-d-wi-ku/app.R')
source('app.R')
source('app.R')
source('app.R')
install.packages("tuneR")
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
runApp()
signum(-10)
library(SparkR)
sign(-5)
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
typeof(1:n)
1:n
(data.frame(Time = 1:n,  Amplitude = 1:n)
data.frame(Time = 1:n,  Amplitude = 1:n)
data.frame(Time = seq(1,n),  Amplitude = seq(1,n))
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
source('app.R')
